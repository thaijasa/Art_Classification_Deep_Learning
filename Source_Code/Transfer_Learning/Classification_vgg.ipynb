{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read X csv file\n",
    "xTrain = pd.read_csv(\"/Users/thaijasa/Documents/Masters/Fall_2018/Large_Scale_Analytics/Project/Dataset_Final/X_train_vgg.csv\")\n",
    "xTrain.drop(['Unnamed: 0'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read Y csv file\n",
    "yTrain = pd.read_csv(\"/Users/thaijasa/Documents/Masters/Fall_2018/Large_Scale_Analytics/Project/Dataset_Final/Y_train_vgg.csv\", header = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import X test\n",
    "xTest = pd.read_csv(\"/Users/thaijasa/Documents/Masters/Fall_2018/Large_Scale_Analytics/Project/Dataset_Final/X_test_vgg.csv\")\n",
    "xTest.drop(['Unnamed: 0'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest = pd.read_csv(\"/Users/thaijasa/Documents/Masters/Fall_2018/Large_Scale_Analytics/Project/Dataset_Final/Y_test_vgg.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain shape:  (7721, 25088)\n",
      "yTrain shape:  (7721, 1)\n",
      "xTest shape:  (856, 25088)\n",
      "yTest shape:  (856, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"xTrain shape: \", xTrain.shape)\n",
    "print(\"yTrain shape: \", yTrain.shape)\n",
    "print(\"xTest shape: \", xTest.shape)\n",
    "print(\"yTest shape: \", yTest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(sampleX, sampleY, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.8761682242990654\n",
      "Latency Time:  20.944372999999985\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.69      0.70      0.70       122\n",
      "   engraving       0.85      0.48      0.61        84\n",
      " iconography       0.93      0.98      0.95       231\n",
      "    painting       0.93      0.92      0.92       228\n",
      "   sculpture       0.87      0.98      0.92       191\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       856\n",
      "   macro avg       0.85      0.81      0.82       856\n",
      "weighted avg       0.88      0.88      0.87       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "clf = clf.fit(xTrain, yTrain)\n",
    "\n",
    "RF_pred = clf.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "RF_F1 = f1_score(yTest,RF_pred,average = \"micro\")\n",
    "RF_LatencyTime = stop_time - start_time\n",
    "RF_ClassReport = classification_report(yTest,RF_pred)\n",
    "\n",
    "print(\"F1-Score: \",RF_F1)\n",
    "print(\"Latency Time: \", RF_LatencyTime)\n",
    "print(\"Classification Report:\\n \",RF_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.7453271028037385\n",
      "Latency Time:  44.77955700000001\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.43      0.48      0.45       122\n",
      "   engraving       0.49      0.49      0.49        84\n",
      " iconography       0.91      0.85      0.88       231\n",
      "    painting       0.83      0.85      0.84       228\n",
      "   sculpture       0.80      0.77      0.79       191\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       856\n",
      "   macro avg       0.69      0.69      0.69       856\n",
      "weighted avg       0.75      0.75      0.75       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DECISION TREES\n",
    "from sklearn import tree\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "c1f = tree.DecisionTreeClassifier()\n",
    "clf = c1f.fit(xTrain, yTrain)\n",
    "\n",
    "Dectree_pred =c1f.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "Dectree_F1 = f1_score(yTest,Dectree_pred,average = \"micro\")\n",
    "Dectree_LatencyTime = stop_time - start_time\n",
    "Dectree_ClassReport = classification_report(yTest,Dectree_pred)\n",
    "\n",
    "print(\"F1-Score: \",Dectree_F1)\n",
    "print(\"Latency Time: \", Dectree_LatencyTime)\n",
    "print(\"Classification Report:\\n \",Dectree_ClassReport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.897196261682243\n",
      "Latency Time:  2391.7529639999993\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.72      0.71      0.72       122\n",
      "   engraving       0.80      0.65      0.72        84\n",
      " iconography       0.96      0.97      0.96       231\n",
      "    painting       0.92      0.96      0.94       228\n",
      "   sculpture       0.94      0.97      0.96       191\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       856\n",
      "   macro avg       0.87      0.85      0.86       856\n",
      "weighted avg       0.89      0.90      0.90       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GRADIENT BOOST\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "c1f = GradientBoostingClassifier()\n",
    "clf = c1f.fit(xTrain, yTrain)\n",
    "\n",
    "GB_pred =c1f.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "GB_F1 = f1_score(yTest,GB_pred,average = \"micro\")\n",
    "GB_LatencyTime = stop_time - start_time\n",
    "GB_ClassReport = classification_report(yTest,GB_pred)\n",
    "\n",
    "print(\"F1-Score: \",GB_F1)\n",
    "print(\"Latency Time: \", GB_LatencyTime)\n",
    "print(\"Classification Report:\\n \",GB_ClassReport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.9100467289719626\n",
      "Latency Time:  14.525869000000057\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.74      0.70      0.72       122\n",
      "   engraving       0.82      0.65      0.73        84\n",
      " iconography       0.97      0.99      0.98       231\n",
      "    painting       0.94      0.96      0.95       228\n",
      "   sculpture       0.94      0.99      0.96       191\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       856\n",
      "   macro avg       0.88      0.86      0.87       856\n",
      "weighted avg       0.91      0.91      0.91       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "c1f = SGDClassifier()\n",
    "clf = c1f.fit(xTrain, yTrain)\n",
    "\n",
    "SGD_pred =c1f.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "SGD_F1 = f1_score(yTest,SGD_pred,average = \"micro\")\n",
    "SGD_LatencyTime = stop_time - start_time\n",
    "SGD_ClassReport = classification_report(yTest,SGD_pred)\n",
    "\n",
    "print(\"F1-Score: \",SGD_F1)\n",
    "print(\"Latency Time: \", SGD_LatencyTime)\n",
    "print(\"Classification Report:\\n \",SGD_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.2827102803738318\n",
      "Latency Time:  308.08673499999986\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.11      0.02      0.04       122\n",
      "   engraving       0.00      0.00      0.00        84\n",
      " iconography       0.92      0.05      0.10       231\n",
      "    painting       0.28      1.00      0.44       228\n",
      "   sculpture       0.00      0.00      0.00       191\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       856\n",
      "   macro avg       0.26      0.21      0.11       856\n",
      "weighted avg       0.34      0.28      0.15       856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "c1f = KNeighborsClassifier(n_neighbors=1000, weights='uniform', algorithm='auto')\n",
    "clf = c1f.fit(xTrain, yTrain)\n",
    "\n",
    "KNN_pred =c1f.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "KNN_F1 = f1_score(yTest,KNN_pred,average = \"micro\")\n",
    "KNN_LatencyTime = stop_time - start_time\n",
    "KNN_ClassReport = classification_report(yTest,KNN_pred)\n",
    "\n",
    "print(\"F1-Score: \",KNN_F1)\n",
    "print(\"Latency Time: \", KNN_LatencyTime)\n",
    "print(\"Classification Report:\\n \",KNN_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.8901869158878505\n",
      "Latency Time:  654.2185359999999\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.72      0.71      0.72       122\n",
      "   engraving       0.85      0.54      0.66        84\n",
      " iconography       0.94      0.99      0.96       231\n",
      "    painting       0.96      0.94      0.95       228\n",
      "   sculpture       0.87      0.98      0.92       191\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       856\n",
      "   macro avg       0.87      0.83      0.84       856\n",
      "weighted avg       0.89      0.89      0.89       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extra Tress Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=2000,n_jobs=-1,criterion='gini',class_weight = 'balanced')\n",
    "clf = clf.fit(xTrain, yTrain)\n",
    "\n",
    "Ext_pred = clf.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "EXT_F1 = f1_score(yTest,Ext_pred,average = \"micro\")\n",
    "EXT_LatencyTime = stop_time - start_time\n",
    "EXT_ClassReport = classification_report(yTest,Ext_pred)\n",
    "\n",
    "print(\"F1-Score: \",EXT_F1)\n",
    "print(\"Latency Time: \", EXT_LatencyTime)\n",
    "print(\"Classification Report:\\n \",EXT_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.8831775700934581\n",
      "Latency Time:  137.22625400000015\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.71      0.71      0.71       122\n",
      "   engraving       0.86      0.52      0.65        84\n",
      " iconography       0.95      0.98      0.96       231\n",
      "    painting       0.94      0.92      0.93       228\n",
      "   sculpture       0.86      0.99      0.92       191\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       856\n",
      "   macro avg       0.86      0.83      0.83       856\n",
      "weighted avg       0.88      0.88      0.88       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "clf = AdaBoostClassifier(RandomForestClassifier(n_estimators=500,n_jobs=-1,criterion='gini',class_weight = 'balanced'))\n",
    "clf = clf.fit(xTrain, yTrain)\n",
    "\n",
    "Adab_pred = clf.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "ADB_F1 = f1_score(yTest,Adab_pred,average = \"micro\")\n",
    "ADB_LatencyTime = stop_time - start_time\n",
    "ADB_ClassReport = classification_report(yTest,Adab_pred)\n",
    "\n",
    "print(\"F1-Score: \",ADB_F1)\n",
    "print(\"Latency Time: \", ADB_LatencyTime)\n",
    "print(\"Classification Report:\\n \",ADB_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.889018691588785\n",
      "Latency Time:  3790.0939260000005\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.68      0.69      0.69       122\n",
      "   engraving       0.77      0.58      0.66        84\n",
      " iconography       0.96      0.97      0.97       231\n",
      "    painting       0.92      0.96      0.94       228\n",
      "   sculpture       0.94      0.97      0.96       191\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       856\n",
      "   macro avg       0.85      0.83      0.84       856\n",
      "weighted avg       0.89      0.89      0.89       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf = clf.fit(xTrain, yTrain)\n",
    "\n",
    "XGB_pred = clf.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "XGB_F1 = f1_score(yTest,XGB_pred,average = \"micro\")\n",
    "XGB_LatencyTime = stop_time - start_time\n",
    "XGB_ClassReport = classification_report(yTest,XGB_pred)\n",
    "\n",
    "print(\"F1-Score: \",XGB_F1)\n",
    "print(\"Latency Time: \", XGB_LatencyTime)\n",
    "print(\"Classification Report:\\n \",XGB_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:618: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.8422897196261683\n",
      "Latency Time:  14201.584047\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.64      0.64      0.64       122\n",
      "   engraving       0.82      0.50      0.62        84\n",
      " iconography       0.89      0.92      0.91       231\n",
      "    painting       0.90      0.91      0.91       228\n",
      "   sculpture       0.84      0.95      0.89       191\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       856\n",
      "   macro avg       0.82      0.78      0.79       856\n",
      "weighted avg       0.84      0.84      0.84       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "clf = BaggingClassifier(n_estimators=500)\n",
    "clf = clf.fit(xTrain, yTrain)\n",
    "\n",
    "Bag_pred = clf.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "Bag_F1 = f1_score(yTest,Bag_pred,average = \"micro\")\n",
    "Bag_LatencyTime = stop_time - start_time\n",
    "Bag_ClassReport = classification_report(yTest,Bag_pred)\n",
    "\n",
    "print(\"F1-Score: \",Bag_F1)\n",
    "print(\"Latency Time: \", Bag_LatencyTime)\n",
    "print(\"Classification Report:\\n \",Bag_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score:  0.8165887850467289\n",
      "Latency Time:  12.176136000000042\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    drawings       0.49      0.50      0.50       122\n",
      "   engraving       0.59      0.68      0.63        84\n",
      " iconography       0.94      0.94      0.94       231\n",
      "    painting       0.96      0.80      0.87       228\n",
      "   sculpture       0.85      0.95      0.90       191\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       856\n",
      "   macro avg       0.77      0.77      0.77       856\n",
      "weighted avg       0.83      0.82      0.82       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(xTrain, yTrain)\n",
    "\n",
    "naive_pred = clf.predict(xTest)\n",
    "\n",
    "stop_time = time.clock()\n",
    "\n",
    "naive_F1 = f1_score(yTest,naive_pred,average = \"micro\")\n",
    "naive_LatencyTime = stop_time - start_time\n",
    "naive_ClassReport = classification_report(yTest,naive_pred)\n",
    "\n",
    "print(\"F1-Score: \",naive_F1)\n",
    "print(\"Latency Time: \", naive_LatencyTime)\n",
    "print(\"Classification Report:\\n \",naive_ClassReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'bar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1aeeee803c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF1Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'bar'"
     ]
    }
   ],
   "source": [
    "#BarChart to compare different F1Scores\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "F1Score =[]\n",
    "label = []\n",
    "\n",
    "F1Score = [RF_F1, Dectree_F1, GB_F1, SGD_F1, KNN_F1, EXT_F1, ADB_F1, XGB_F1, Bag_F1, naive_F1]\n",
    "label = ['RF','DT','GB','SGD','KNN','EXT','ADB','XGB','Baagging','NaiveBayes']\n",
    "\n",
    "x_axis = np.arange(len(F1Score))\n",
    "y_axis = F1Score\n",
    "\n",
    "plt.bar(x_axis, y_axis, color = 'red')\n",
    "plt.xticks(x_axis, label, fontsize=20)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('F1Score')\n",
    "plt.title('Comparison of F1 scores between 10 selected algorithms')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time comparison\n",
    "TimeComparison = []\n",
    "TimeComparison = [RF_LatencyTime, Dectree_LatencyTime, GB_LatencyTime, SGD_LatencyTime, KNN_LatencyTime, EXT_LatencyTime, ADB_LatencyTime, XGB_LatencyTime, Bag_LatencyTime, naive_LatencyTime] \n",
    "\n",
    "plt.bar(label,Time, color = 'blue')\n",
    "plt.xticks(x_axis, label, fontsize=20)\n",
    "plt.ylabel('Latency Time')\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.title('Comparison of Latency Time between 10 selected algorithms')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
